---
title: "WALS Data Assignment"
output: html_notebook
---

## Import & View Dataset

```{r}
getwd()
data <- read.csv("wals-data.csv")
cat("Number of rows:", nrow(data)) #dos puntos
cat("Number of columns:", ncol(data))
head(data)
```

#### Features of Interest

```{r}
features_of_interest <- c("Absence of Common Consonants", "Lateral Consonants")
```

#### Look at the parameters

Let's first have a look at what exactly the columns contain.

```{r}
for (feature in features_of_interest) {
  cat("\n", feature)
  feature_col <- data[data$Parameter_name==feature, c("Value")]
  cat("\n NROWS: ", sum(!is.na(feature_col)))
}

# if it's a dataframe (2D), use distinct to return without duplicates
# if it's a vector (1D), use unique to return without duplicates
unique_languages <- unique(data$Language_ID)
cat("\n\n Number of unique languages:", length(unique_languages), "\n")

feature_names <- unique(data$Parameter_name)
print("Here are a few example variables...")
feature_names
cat("Number of variables: ", length(feature_names), "\n")

num_languages <- length(unique(data$Language_ID))
cat("Number of languages in the dataset: ", num_languages, "\n")
```

```{r}

data[data$Parameter_name=="Consonant-Vowel Ratio" & data$Language_name=="Polish",]
data[data$Parameter_name=="Tone",]

data[data$Parameter_name=="Absence of Common Consonants", c("Language_ID", "Value")]
```

## Creating Columns for interesting features

Our data, as is usually the case, is not structured in the optimal way for our specific use case. Therefore, we must look to cleaning and transforming the dataset in order to mold it to the shape that we require. In order to do this, we will choose some features that we are interested in from the "Parameter_name" column and convert them into their own column. For this, it may be better to have the Parameter names converted to a more suitable format for a dataset column. The following functions will do some small operations on the original string to convert "Asymmetric Case-Marking" to "asymmetric_case_marking", for instance.

```{r}
get_simplified_feature_name <- function(s) {
  updated_col_name <- s %>% 
      tolower() %>% 
      str_replace_all(" ", "_") %>% 
      str_replace_all("-", "_")
  return (updated_col_name)
}
```

We can't just combine columns because not every language has a value for every feature. This would lead to the language feature values being assigned to the wrong languages. Therefore, we will create a base table with **Language_ID** and **Language_name**. Any columns added will have to include the Language_ID, known as a *primary key*. Therefore, the base table will have columns added to it based on the Language_ID.

```{r}
library(dplyr)
library(stringr)

# what are some variables that will not change throughout the analyses?
PARAMS_FOR_SUBSET <- c("Language_ID", "Value")
BASE_COLS <- c("Language_ID", "Language_name")
PRIMARY_KEY <- BASE_COLS[1]
VAL_COL <- "Value"
PARAMETER_NAME_COL <- "Parameter_name"

# iterate through each interesting feature and create a
# new column with the values from that feature by merging
# based on our primary key "Language_ID"
split_features_from_dataset <- function(data, 
                                        features,
                                        parameters_for_subset, 
                                        base_table_cols,
                                        primary_key) {
  base_df <- distinct(data[, BASE_COLS]) # immutable, always remains a reference table
  output_df <- base_table # starts off as the reference table (a copy) and grows
  
  for (feature in features) {
    specific_parameter_subset <- data[data[[PARAMETER_NAME_COL]] == feature, parameters_for_subset]
    
    # we want to keep all rows in the base table (we don't want to remove any languages yet, so all.x = TRUE
    # any languages which don't have a value for the feature we're interested in
    # will just have "NA"
    intermediate_df <- merge(x = base_df, y = specific_parameter_subset, by = primary_key, all.x = TRUE)
    
    # change the merged column name from 'Value' to our feature
    updated_col_name <- get_simplified_feature_name(feature)
    output_df[[updated_col_name]] <- intermediate_df[[VAL_COL]]
  }
  return (output_df)
}

remove_na_rows <- function(df) {
  return (df[complete.cases(df),])
}

transform_data <- function(data, predictors, response) {
  predictors_col_name <- lapply(predictors, get_simplified_feature_name)
  response_col_name <- get_simplified_feature_name(response)
  features <- c(predictors, response)
  
  transformed_df <- split_features_from_dataset(data,
                                                features,
                                                PARAMS_FOR_SUBSET,
                                                BASE_COLS,
                                                PRIMARY_KEY)
  
  # remove any rows which don't contain a value for both features
  transformed_df <- remove_na_rows(transformed_df)
  
  # ensure the respones variable is interpreted as the correct type
  transformed_df[[response_col_name]] <- as.factor(transformed_df[[response_col_name]])
  
  return (transformed_df)
}

get_response_predictor_formula <- function(response, predictors) {
  formula <- paste(response, paste(" ~ ", paste(predictors, collapse = " + ")))
  return (formula)
}
```

### Predicting Categorical Features

We will build a **Multinomial Logistic Regression model**. We require a train dataset and a test dataset, one for fitting data to the model and then a previously unseen one for testing whether that model has done a good job of generalising and has not been overfitted.

First let's create a function that partitions our data.

```{r}
set.seed(1000)

split_train_test <- function(df, response, prop_train) {
  train_indices <- sample(1:nrow(df), nrow(df)*0.7)
  # train_indices = createDataPartition(df[[response]], p = prop_train, list = FALSE)
  train_set <- df[train_indices, ]
  test_set <- df[-train_indices, ]
  return (list(train_set, test_set))
}
```

We will also need to create a *formula* which is passed to the MLR model, e.g *response \~ predictor_A + predictor_B*, which would predict the variable *response* based on the two features *predictor_A* and *predictor_B*. This formula can be created as a string with the following function:

```{r}
get_response_predictor_formula <- function(response, predictors) {
  formula <- paste(response, paste(" ~ ", paste(predictors, collapse = " + ")))
  return (formula)
}
```

## Model 1: Does presence/absence of common consonants indicate whether laterals are present?

Testing whether lateral consonants are common. input: "Absence of Common Consonants", output: "Lateral Consonants".

```{r}
library(nnet)
library(caret)

# Building Model 1
predictors <- c("Absence of Common Consonants")
response <- "Lateral Consonants"

predictors_col_name <- lapply(predictors, get_simplified_feature_name)
response_col_name <- get_simplified_feature_name(response)

# transform the data
transformed_df_m1 <- transform_data(data, predictors, response)

# create a train/test set
train_test_data_m1 <- split_train_test(df = transformed_df_m1, response = response_col_name, prop_train = 0.7)
train_set_m1 <- train_test_data_m1[[1]]
test_set_m1 <- train_test_data_m1[[2]]

# create the formula for the response/predictor relationship e.g response ~ predictor_A + predictor_B
multinom_feature_formula_m1 <- get_response_predictor_formula(response_col_name, predictors_col_name)

# create a multi-nomial logistic regression model
model_m1 <- multinom(multinom_feature_formula_m1, data = train_set_m1)

# run predictions with the test set
test_set_m1
predictions_multinom_m1 <- predict(model_m1, newdata = test_set_m1, type="class")

# create a confusion matrix to see the results
cm_m1 <- confusionMatrix(predictions_multinom_m1, as.factor(test_set_m1[[response_col_name]]))
print(cm_m1)
```

## Model 2: Do stress features indicate whether a language has tone?

If you have these inputs, you may not have tone. Input: Fixed Stress Locations, Weight-Sensitive Stress (check values) Output: Tone
```{r}
# Building Model 1
predictors <- c("Fixed Stress Locations", "Weight-Sensitive Stress")
response <- "Tone"

predictors_col_name <- lapply(predictors, get_simplified_feature_name)
response_col_name <- get_simplified_feature_name(response)

# transform the data
transformed_df_m2 <- transform_data(data, predictors, response)

# create a train/test set
train_test_data_m2 <- split_train_test(df = transformed_df_m2, response = response_col_name, prop_train = 0.7)
train_set_m2 <- train_test_data_m2[[1]]
test_set_m2 <- train_test_data_m2[[2]]

# create the formula for the response/predictor relationship e.g response ~ predictor_A + predictor_B
multinom_feature_formula_m2 <- get_response_predictor_formula(response_col_name, predictors_col_name)

# create a multi-nomial logistic regression model
model_m2 <- multinom(multinom_feature_formula_m2, data = train_set_m2)

# run predictions with the test set
test_set_m2
predictions_multinom_m2 <- predict(model_m2, newdata = test_set_m2, type="class")

# create a confusion matrix to see the results
cm_m2 <- confusionMatrix(predictions_multinom_m2, as.factor(test_set_m2[[response_col_name]]))
print(cm_m2)
```

## Model 3: Do glottals or uvular consonants indicate whether a language has uncommon consonants?

Input: Glottalised Consonants, Uvular Consonants Output: Presence of Uncommon Consonants

```{r}
# Building Model 3
predictors <- c("Glottalized Consonants", "Uvular Consonants")
response <- "Presence of Uncommon Consonants"

predictors_col_name <- lapply(predictors, get_simplified_feature_name)
response_col_name <- get_simplified_feature_name(response)

# transform the data
transformed_df_m2 <- transform_data(data, predictors, response)

# create a train/test set
train_test_data_m2 <- split_train_test(df = transformed_df_m2, response = response_col_name, prop_train = 0.7)
train_set_m2 <- train_test_data_m2[[1]]
test_set_m2 <- train_test_data_m2[[2]]

# create the formula for the response/predictor relationship e.g response ~ predictor_A + predictor_B
multinom_feature_formula_m2 <- get_response_predictor_formula(response_col_name, predictors_col_name)

# create a multi-nomial logistic regression model
model_m2 <- multinom(multinom_feature_formula_m2, data = train_set_m2)

# run predictions with the test set
test_set_m2
predictions_multinom_m2 <- predict(model_m2, newdata = test_set_m2, type="class")

# create a confusion matrix to see the results
cm_m2 <- confusionMatrix(predictions_multinom_m2, as.factor(test_set_m2[[response_col_name]]))
print(cm_m2)
```
